variable <- c(1,2,3,4,5,6)
(variable)
variable <- c(100,2,323,4,1,43)
summary(variable)
vector.1 <- seq(2,4,by=.5)
print(rev(vector.1))
print(unique(vector.1))
print(table(vector.1))
print(table(vector.1))
print(matrix(2,nrow = 2, ncol = 2))
df <- data.frame(etiquetas=c("Nombre","Apellido","DNI"), persona1=c("Pedro","Fernández"."2323"))
(etiquetas=c("Nombre","Apellido","DNI"), persona1=c("Pedro","Fernández","2323"))
df <- data.frame(Nombre= c("María","Pilar", "Enrique"), apellidos=c("García", "Pérez","Ferández"), DNI = c("322","121","545"))
print(view(df))
View(df)
view$Nombre
df$Nombre
df[[1]]
df[1,1]
rownames(df)
colnames(df)
trabajo <- c("Arquitecta", "Biotecnóloga","Filóloga")
cbind(df, trabajo)
View(df)
df_ampliado <- cbind(df, trabajo)
View(df_ampliado)
dim(df_ampliado)
(list=ls())
rm(list=ls())
x <- 1:4
y <- 6:9
z <- x+y
print(z)
rm(list=ls())
rm(list=ls())
x <- 1;4
x <- 1:4
x > 2
x <- 1:4
y <- 6:9
z <- x+y
print(z)
rm(list=ls())
rm(list=ls())
matrix(c(7,0,0,0,7,0),3,2)
matrix(c(7,0,0,0,7,0),2,3)
library(glmnet)
setwd("C:/Users/crist/Desktop/equipo2_lote7_shared_repo")
df <- read.csv("1_data/datos.csv")
getwd()
#Estructurar el Dataframe
clases <- read.csv("1/data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
#Estructurar el Dataframe
clases <- read.csv("1_data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
columnas <- read_lines("1_data/column_names.txt")
library(readr)
columnas <- read_lines("1_data/column_names.txt")
View(clases)
gen_exp <-read.csv("1_data/gene_expression.csv", header = FALSE, sep = ";", col.names = (columnas))
View(gen_exp)
datos <- cbind(clases, gen_exp)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
View(datos)
class(datos)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
datos$Clase <- as.factor(datos$Clase)
str(datos)
ceros <- colnames(datos[,2:501])[colSums(datos[,2:501]) ==0] #Que genes dan 0
datos_imputados <- datos[, !colnames(datos) %in% ceros] #Quitamos ceros
datos_imputados <- datos[, colSums(datos[,2:501]) != 0] #Quitamos ceros (más simple)
datos #Ha removido 3 variables
View(datos)
class(datos)
any(colSums(df[ ,sapply(df, is.numeric)]) == 0)
any(colSums(datos[ ,sapply(datos, is.numeric)]) == 0)
clases <- read.csv("1_data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
columnas <- read_lines("1_data/column_names.txt")
gen_exp <-read.csv("1_data/gene_expression.csv", header = FALSE, sep = ";", col.names = (columnas))
datos <- cbind(clases, gen_exp)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
datos$Clase <- as.factor(datos$Clase)
str(datos)
ceros <- colnames(datos[,2:501])[colSums(datos[,2:501]) ==0] #Que genes dan 0
datos_imputados <- datos[, !colnames(datos) %in% ceros] #Quitamos ceros
datos_imputados <- datos[, colSums(datos[,2:501]) != 0] #Quitamos ceros (más simple)
datos #Ha removido 3 variables
any(colSums(datos[ ,sapply(datos, is.numeric)]) == 0)
ceros
#al ejecutar esto
any(colSums(datos[ ,sapply(datos,is.numeric)]) == 0)
datos <- datos[ ,colSums(df) !=0]
#######################Aporte Cris#############################################
#al ejecutar esto
any(colSums(datos_imputados[ ,sapply(datos_imputados,is.numeric)]) == 0) ##sigue habiendo columnas con 0
dim(datos)
dim(datos_imputados)
#######################Aporte Cris#############################################
#al ejecutar esto
any(colSums(datos_imputados[ ,sapply(datos_imputados,is.numeric)]) == 0) ##sigue habiendo columnas con 0
datos <- datos[ ,colSums(datos) !=0]
#######################Aporte Cris#############################################
#al ejecutar esto
any(colSums(datos_imputados[ ,sapply(datos_imputados,is.numeric)]) == 0) ##sigue habiendo columnas con 0
rm(list = ls())
library(readr)
#Estructurar el Dataframe
clases <- read.csv("1_data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
columnas <- read_lines("1_data/column_names.txt")
gen_exp <-read.csv("1_data/gene_expression.csv", header = FALSE, sep = ";", col.names = (columnas))
datos <- cbind(clases, gen_exp)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
datos$Clase <- as.factor(datos$Clase)
str(datos)
ceros <- colnames(datos[,2:501])[colSums(datos[,2:501]) ==0] #Que genes dan 0
datos_imputados <- datos[, !colnames(datos) %in% ceros] #Quitamos ceros
datos_imputados <- datos[, colSums(datos[,2:501]) != 0] #Quitamos ceros (más simple)
datos #Ha removido 3 variables
#######################Aporte Cris#############################################
#al ejecutar esto
any(colSums(datos_imputados[ ,sapply(datos_imputados,is.numeric)]) == 0) ##sigue habiendo columnas con 0
class(gene_exp)
class(gen_exp)
genes <- gen_exp[ ,colSums(gen_exp) != 0]
df <- cbind(clases, genes)
View(df)
class(df)
any(is.na(df))
any(colSums(df[ ,sapply(df,is.numeric)]) == 0)
dim(df)
rm(list = ls())
library(readr)
clases <- read.csv("1_data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
columnas <- read_lines("1_data/column_names.txt")
gen_exp <-read.csv("1_data/gene_expression.csv", header = FALSE, sep = ";", col.names = (columnas))
datos <- cbind(clases, gen_exp)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
datos$Clase <- as.factor(datos$Clase)
str(datos)
ceros <- colnames(datos[,2:501])[colSums(datos[,2:501]) ==0] #Que genes dan 0
datos_imputados <- datos[, !colnames(datos) %in% ceros] #Quitamos ceros
datos_imputados <- datos[, colSums(datos[,2:501]) != 0] #Quitamos ceros (más simple)
dim(datos)
dim(datos_imputados)
any(colSums(datos_imputados[ ,sapply(datos_imputados, is.numeric)]) == 0)
sum(colSums(datos_imputados[ ,sapply(datos_imputados, is.numeric)]) == 0)
names(sum(colSums(datos_imputados[ ,sapply(datos_imputados, is.numeric)]) == 0))
names(colSums(datos_imputados[ ,sapply(datos_imputados, is.numeric)]) == 0)
any(colSums(datos_imputados[ ,sapply(datos_imputados, is.numeric)]) == 0)
ceros
datos_imputados$MIER3
genes <- gen_exp[ ,colSums(gen_exp) != 0] #sobre df con todo numeros, quitamos las columnas con todo 0
genes <- scale(genes) #escalamos tambien
df <- cbind(clases, genes)
any(is.na(df)) #no datos faltantes
any(colSums(df[ ,sapply(df,is.numeric)]) == 0) #ya no hay columnas con todo 0
dim(df) #ahora si que se han eliminado las variables con todo 0
write.csv("datos")
write.csv("df.csv")
write.csv("1_data/df.csv")
write.csv(df,"1_data/df.csv")
View(df)
rm(list = ls())
df <- read.csv("1_data/df.csv")
View(df)
any(colSums(df[ ,sapply(df, is.numeric)]) =0 0)
any(colSums(df[ ,sapply(df, is.numeric)]) ==0)
#librerias
library(caret)
install.packages("randomForest")
library(randomForest)
library(MASS)
View(df)
View(df)
dim(df)
View(df)
x <- as.matrix(df[ ,4:499])
View(x)
x <- as.matrix(df[ ,3:499])
y <- as.factor(df$Clase)
library(glmnet)
#Base de datos tratada
df <- read.csv("1_data/df.csv")
lasso.result <- cv.glmnet(x,y, family = "multinomial", alpha = 1)
lasso.coef <- coef(lasso.result, s = "lambda.min")
coeff_AGH <- as.matrix(lasso.coef[["AGH"]])
coeff_CFB <- as.matrix(lasso.coef[["CFB"]])
coeff_CGC <- as.matrix(lasso.coef[["CGC"]])
coeff_CHC <- as.matrix(lasso.coef[["CHC"]])
coeff_HPB <- as.matrix(lasso.coef[["HPB"]])
coef_AGH_df <- as.data.frame(coeff_AGH)
coef_CFB_df <- as.data.frame(coeff_CFB)
coef_CGC_df <- as.data.frame(coeff_CGC)
coef_CHC_df <- as.data.frame(coeff_CHC)
coef_HPB_df <- as.data.frame(coeff_HPB)
colnames(coef_AGH_df) <- "AGH"
colnames(coef_CFB_df) <- "CFB"
colnames(coef_CGC_df) <- "CGC"
colnames(coef_CHC_df) <- "CHC"
colnames(coef_HPB_df) <- "HPB"
df_final <- cbind(coef_AGH_df, coef_CFB_df, coef_CGC_df, coef_CHC_df, coef_HPB_df)
df_final <- df_final[2:199, ] #quitar el intercept
#Quitamos variables donde para todos los niveles el valor sea 0
df_final_2 <- df_final[rowSums(df_final) != 0, ]
#recuperamos el nombre de aquellas variables que hemos seleccionado con LASSO
variables_elegidas <- rownames(df_final_2)
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(clases, all_of(variables_elegidas))
#librerias
library(dplyr)
library(caret)
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(clases, all_of(variables_elegidas))
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(Clase, all_of(variables_elegidas))
dim(df_analisis)
View(df_final)
rm(list = ls())
library(dplyr)
library(caret)
library(randomForest)
library(MASS)
library(glmnet)
#Base de datos tratada
df <- read.csv("1_data/df.csv")
View(df)
dim(df) #Tenemos muchas variables > podemos aplicar LASSO para quedarnos con el subconjunto de variables mas optimo
##########LASSO##################################
x <- as.matrix(df[ ,3:499])
y <- as.factor(df$clases)
lasso.result <- cv.glmnet(x,y, family = "multinomial", alpha = 1)
y <- as.factor(df$clases)
y <- as.factor(df$clase)
lasso.result <- cv.glmnet(x,y, family = "multinomial", alpha = 1)
rm(list = ls())
library(dplyr)
library(caret)
library(randomForest)
library(MASS)
library(glmnet)
#Base de datos tratada
df <- read.csv("1_data/df.csv")
View(df)
##########LASSO##################################
x <- as.matrix(df[ ,3:499])
View(x)
dim(df)
dim8x
dim(x)
y <- as.factor(df$Clase)
lasso.result <- cv.glmnet(x,y, family = "multinomial", alpha = 1)
lasso.coef <- coef(lasso.result, s = "lambda.min")
coeff_AGH <- as.matrix(lasso.coef[["AGH"]])
coeff_CFB <- as.matrix(lasso.coef[["CFB"]])
coeff_CGC <- as.matrix(lasso.coef[["CGC"]])
coeff_CHC <- as.matrix(lasso.coef[["CHC"]])
coeff_HPB <- as.matrix(lasso.coef[["HPB"]])
coef_AGH_df <- as.data.frame(coeff_AGH)
coef_CFB_df <- as.data.frame(coeff_CFB)
coef_CGC_df <- as.data.frame(coeff_CGC)
coef_CHC_df <- as.data.frame(coeff_CHC)
coef_HPB_df <- as.data.frame(coeff_HPB)
colnames(coef_AGH_df) <- "AGH"
colnames(coef_CFB_df) <- "CFB"
colnames(coef_CGC_df) <- "CGC"
colnames(coef_CHC_df) <- "CHC"
colnames(coef_HPB_df) <- "HPB"
df_final <- cbind(coef_AGH_df, coef_CFB_df, coef_CGC_df, coef_CHC_df, coef_HPB_df)
df_final <- df_final[2:199, ] #quitar el intercept
View(df_final)
#Quitamos variables donde para todos los niveles el valor sea 0
df_final_2 <- df_final[rowSums(df_final) != 0, ]
#recuperamos el nombre de aquellas variables que hemos seleccionado con LASSO
variables_elegidas <- rownames(df_final_2)
dim(df_analisis)
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(Clase, all_of(variables_elegidas))
dim(df_analisis)
class(df_analisis$C22orf15)
View(df_analisis)
#######DIVISION DEL DATASET EN DATOS ENTRENAMIENTO Y PRUEBA (HOLD-OUT MODEL)
#convertir a variable categorica
df_analisis$clases <- factor(df_analisis$clases)
#######DIVISION DEL DATASET EN DATOS ENTRENAMIENTO Y PRUEBA (HOLD-OUT MODEL)
#convertir a variable categorica
df_analisis$clase <- factor(df_analisis$clase)
#######DIVISION DEL DATASET EN DATOS ENTRENAMIENTO Y PRUEBA (HOLD-OUT MODEL)
#convertir a variable categorica
df_analisis$clase <- as.factor(df_analisis$clase)
class(df$Clase)
class(df_analisis$Clase)
#######DIVISION DEL DATASET EN DATOS ENTRENAMIENTO Y PRUEBA (HOLD-OUT MODEL)
#convertir a variable categorica
df_analisis$Clase <- as.factor(df_analisis$Clase)
class(df_analisis$Clase)
table(df_analisis$Clase)
dim(df_analisis)
#Seguimos preparando el dataset >  separamos  en conjunto de entrenamiento y conjunto de prueba
index_train <- createDataPartition(df_analisis$clases, p = 0.8, list = FALSE)
#Seguimos preparando el dataset >  separamos  en conjunto de entrenamiento y conjunto de prueba
index_train <- createDataPartition(df_analisis$Clase, p = 0.8, list = FALSE)
df_train <- df_analisis[index_train, ]
df_test <- df_analisis[-index_train, ]
View(df_train)
View(df_test)
dim(df_train)
dim(df_test)
View(df_analisis)
#Para los metodos de analisis del discriminante,  hay que aplicar una formula:
formula  <- as.formula(paste("Clase ~ ",paste(variables_elegidas, collapse = "+")))
formula
install.packages("klaR")
library(kLAR)
library(klaR)
fda.result <- rda(formula, data = df_train)
fda.prediction <- predict(fda.result, newdata = df_test)
fda.clases <- fda.prediction$class
probabilidades.fda <-  fda.prediction$posterior
clases.reales <- df_test$Clase
matriz.fda <- confusionMatrix(fda.clases, clases.reales)
matriz.fda
svm.result <- train(Clase ~., data = df_train, method = "svmLinear",
trControl = trainControl(method = "cv", number = 5),
prob.model = TRUE, tuneGrid = expand.grid(C =seq(1,10,0.5)))
plot(svm.result) #para ir mirando el valor apropiado de C
svm.result <- train(Clase ~., data = df_train, method = "svmLinear",
trControl = trainControl(method = "cv", number = 5),
prob.model = TRUE, tuneGrid = expand.grid(C =seq(1,20,0.5)))
plot(svm.result) #para ir mirando el valor apropiado de C
svm.prediction <- predict(svm.result, newdata = df_test)
svm.probabilidades <- predict(svm.result, newdata = df_test, type = "prob")
matriz.svm <- confusionMatrix(svm.prediction, clases.reales)
matriz.svm
randomforest.result <- train(Clase ~., data = df_train, method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneLength = 30)
plot(randomforest.result)
randomforest.prediction <- predict(randomforest.result, newdata = df_test)
rf.probabilidades <- predict(randomforest.result, newdata = df_test, type = "prob")
rf.matriz <- confusionMatrix(randomforest.prediction,  clases.reales)
rf.matriz
#######CURVAS ROC#####################################################################
#Este ejemplo se trata de un problema multiclase:
table(df$Clase)
library(pROC)
#######DIVISION DEL DATASET EN DATOS ENTRENAMIENTO Y PRUEBA (HOLD-OUT MODEL)
rda.result <- rda(formula, data = df_train)
rda.prediction <- predict(rda.result, newdata = df_test)
rda.clases <- rda.prediction$class
clases.reales <- df_test$Clase
probabilidades.rda <-  rda.prediction$posterior
matriz.rda <- confusionMatrix(rda.clases, clases.reales)
matriz.rda
curva_rda <- multiclass.roc(df_test$clases, as.matrix(probabilidades.rda))
curva_rda <- multiclass.roc(df_test$Clase, as.matrix(probabilidades.rda))
curva_svm <- multiclass.roc(df_test$Clase, as.matrix(svm.probabilidades))
curva_rf <- multiclass.roc(df_test$Clase, as.matrix(rf.probabilidades))
curva_rda$auc
curva_svm$auc
curva_rf$auc
varImp(randomforest.result)
varImpPlot(randomforest.result)
varImpPlot(randomforest.result$finalModel)
rm(list = ls())
library(dplyr)
library(caret)
library(randomForest)
library(klaR)
library(glmnet)
library(pROC)
df <- read.csv("1_data/df.csv")
dim(df) #Tenemos muchas variables > podemos aplicar LASSO para quedarnos con el subconjunto de variables mas optimo
x <- as.matrix(df[ ,3:499])
y <- as.factor(df$Clase)
lasso.result <- cv.glmnet(x,y, family = "multinomial", alpha = 1)
lasso.coef <- coef(lasso.result, s = "lambda.min")
# Convertir los coeficientes a matrices
coeff_AGH <- as.matrix(lasso.coef[["AGH"]])
coeff_CFB <- as.matrix(lasso.coef[["CFB"]])
coeff_CGC <- as.matrix(lasso.coef[["CGC"]])
coeff_CHC <- as.matrix(lasso.coef[["CHC"]])
coeff_HPB <- as.matrix(lasso.coef[["HPB"]])
# Convertir las matrices a dataframes, conservando los nombres de las variables
coef_AGH_df <- as.data.frame(coeff_AGH)
coef_CFB_df <- as.data.frame(coeff_CFB)
coef_CGC_df <- as.data.frame(coeff_CGC)
coef_CHC_df <- as.data.frame(coeff_CHC)
coef_HPB_df <- as.data.frame(coeff_HPB)
# Asegurarse de que los nombres de las variables estén en las columnas
colnames(coef_AGH_df) <- "AGH"
colnames(coef_CFB_df) <- "CFB"
colnames(coef_CGC_df) <- "CGC"
colnames(coef_CHC_df) <- "CHC"
colnames(coef_HPB_df) <- "HPB"
# Combinar los dataframes
df_final <- cbind(coef_AGH_df, coef_CFB_df, coef_CGC_df, coef_CHC_df, coef_HPB_df)
df_final <- df_final[2:199, ] #quitar el intercept
#Quitamos variables donde para todos los niveles el valor sea 0
df_final_2 <- df_final[rowSums(df_final) != 0, ]
#recuperamos el nombre de aquellas variables que hemos seleccionado con LASSO
variables_elegidas <- rownames(df_final_2)
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(Clase, all_of(variables_elegidas))
dim(df_analisis) #nos hemos quedado solo con 36 variables, os parecen demasiado pocas??????
#convertir a variable categorica
df_analisis$Clase <- as.factor(df_analisis$Clase)
#Separar en conjunto de entrenamiento y conjunto de prueba
index_train <- createDataPartition(df_analisis$Clase, p = 0.8, list = FALSE)
df_train <- df_analisis[index_train, ]
df_test <- df_analisis[-index_train, ]
#Para los metodos de analisis del discriminante,  hay que aplicar una formula:
formula  <- as.formula(paste("Clase ~ ",paste(variables_elegidas, collapse = "+")))
rda.result <- rda(formula, data = df_train)
rda.prediction <- predict(rda.result, newdata = df_test)
rda.clases <- rda.prediction$class
clases.reales <- df_test$Clase
probabilidades.rda <-  rda.prediction$posterior
matriz.rda <- confusionMatrix(rda.clases, clases.reales)
matriz.rda
#Como el RDA ha ido bien > parece que los datos tienen relaciones lineales > usamos la variable lineal
svm.result <- train(Clase ~., data = df_train, method = "svmLinear",
trControl = trainControl(method = "cv", number = 5),
prob.model = TRUE, tuneGrid = expand.grid(C =seq(1,20,0.5)))
plot(svm.result) #para ir mirando el valor apropiado de C
svm.prediction <- predict(svm.result, newdata = df_test)
svm.probabilidades <- predict(svm.result, newdata = df_test, type = "prob")
matriz.svm <- confusionMatrix(svm.prediction, clases.reales)
matriz.svm
#Es mas costoso computacionalmente, pero puede merecer la pena usar un metodo mas robusto para compararlo con los otros dos mas simples
randomforest.result <- train(Clase ~., data = df_train, method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneLength = 30)
plot(randomforest.result)
randomforest.prediction <- predict(randomforest.result, newdata = df_test)
rf.probabilidades <- predict(randomforest.result, newdata = df_test, type = "prob")
rf.matriz <- confusionMatrix(randomforest.prediction,  clases.reales)
rf.matriz
varImp(randomforest.result) #variables mas importantes en el modelo
varImpPlot(randomforest.result$finalModel)
#Este ejemplo se trata de un problema multiclase:
table(df$Clase)
#No se pueden usar curvas ROC ni PR como tal > solo cuando hay dos clases
#Pero si que podemos usar multiclass.roc
curva_rda <- multiclass.roc(df_test$Clase, as.matrix(probabilidades.rda))
curva_svm <- multiclass.roc(df_test$Clase, as.matrix(svm.probabilidades))
curva_rf <- multiclass.roc(df_test$Clase, as.matrix(rf.probabilidades))
curva_rda$auc
curva_svm$auc
curva_rf$auc
curva_rda$auc
curva_svm$auc
curva_rf$auc
curva_rda$auc
curva_svm$auc
curva_rf$auc
analisis <- data.frame(metodos =1:3, AUC = 1:3)
View(analisis)
metodos <- c("RDA", "SVM","RF")
analisis <- data.frame(modelos = metodos,  AUC =rep(NA, times = 3))
View(analisis)
areas <- c(curva_rda$auc,curva_svm$auc, curva_rf$auc)
areas
analisis <- data.frame(modelos = metodos,  AUC = areas)
View(analisis)
rm(list = ls())
library(readr)
clases <- read.csv("1_data/classes.csv", header = FALSE, sep = ";", col.names = c("Muestra", "Clase"), row.names = 1)
columnas <- read_lines("1_data/column_names.txt")
gen_exp <-read.csv("1_data/gene_expression.csv", header = FALSE, sep = ";", col.names = (columnas))
datos <- cbind(clases, gen_exp)
#Imputación
sum(is.na(datos)) #En principio no hay NAs
datos$Clase <- as.factor(datos$Clase)
str(datos)
ceros <- colnames(datos[,2:501])[colSums(datos[,2:501]) ==0] #Que genes dan 0
datos_imputados <- datos[, !colnames(datos) %in% ceros] #Quitamos ceros
datos_imputados <- datos[, colSums(datos[,2:501]) != 0] #Quitamos ceros (más simple)
datos #Ha removido 3 variables
#######################Aporte Cris#############################################
#al ejecutar esto
any(colSums(datos_imputados[ ,sapply(datos_imputados,is.numeric)]) == 0) ##sigue habiendo columnas con 0
ceros
datos_imputados$MIER3
datos$MIER3
