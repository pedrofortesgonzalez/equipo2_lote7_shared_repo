#############################
df_d_pca <- cbind(df_genes, df_pca_scores) # concatenamos df de expresión génica y df con las pcs
reset_gtsummary_theme() # resetear opciones de tema para gtsummary
theme_gtsummary_compact() # usar tema `Compact` en gtsummary
# Defino vectors con nombres de vars
gene_varnames <- c(names(df_genes))
pca_varnames <- names(df_pca_scores)
d_pca_varnames <- names(df_d_pca)
strata_vars <- c("PC1", "PC2", "PC3", "PC4", "PC5")
by_vars <- c("TPC1", "TPC2", "TPC3", "TPC4", "TPC5")
result_list <- map2(strata_vars, by_vars, ~ {
df_d_pca %>%
# Seleccionar solo las columnas relevantes: x es la PC, y es su col de terciles
dplyr::select(all_of(gene_varnames), .y) %>%
# Construimos tabla con tbl_summary
tbl_summary(by = .y, # estratificar en función de 3-iles
statistic = all_continuous() ~ "{median} ({p25}, {p75})", #mediana + IQR
# digitos en scientific notation
digits = all_continuous() ~ function(x) format(x, digits = 2, scientific = TRUE),
missing = "no") %>%  # excluir NAs
# Prueba de Kruskal-Wallis solo a vars de expresión génica
add_p(test = all_continuous() ~ "kruskal.test", include = all_of(gene_varnames)) %>%
# añadir corrección de pvalue para disminuir falsos positivos
add_q(method = "bonferroni", pvalue_fun = NULL, quiet = NULL) %>%
bold_p(t = 0.05, q = TRUE) #destacar pvalues significativos en negrita
})
# Convertir cada tabla en result_list a gt
gt_tables <- map(result_list, as_gt)
# Imprimir cada tabla individualmente (guardadas en documento adjunto)
#walk(gt_tables, print)
# Guardar cada tabla individualmente como .html
#walk2(gt_tables, seq_along(gt_tables), ~ gtsave(.x, filename = paste0("4_tables/Tabla 3 - Descriptiva PC", .y, ".html")))
# las variables factor están en tipo character, tengo que convertirlas a numérico pq glmnet no admite tipo factor
# casteo a numérico variables char
df_nogenes <- df %>% dplyr::select(-starts_with("AQ_"), -X, -id, -extension) # df de vars q no son genes
df_char <- df_nogenes[ ,sapply(df_nogenes, is.character)]# guardamos las vars factor en un vector lógico
df_char$antiemesis <- as.character(ifelse(df$corticoides=="antiemesis", "1", "0"))
df_char$corticoides <- as.character(ifelse(df$corticoides=="si", "1", "0"))
df_nochar <- df_nogenes[, sapply(df_nogenes, is.numeric)]
df_nochar <- as.data.frame(scale(df_nochar, center=TRUE, scale=TRUE))
# convierto variables tipo char a factor y luego a numeros para codificarlas de manera que glmnet las entienda
for (i in colnames(df_char)) {
df_char[[i]] <-as.numeric(as.factor(df_char[[i]]))
}
# y concateno df_char, df_nochar y df5 pcs en df_lasso
df_regularizacion <- cbind(df_char, df_nochar)
# ahora tb dejo bien formateada la variable respuesta
df$metastasis = as.factor(as.numeric(ifelse(df$extension == "metastasico", 1, 0)))
# defino variables para df_lasso
cols = c(colnames(df_regularizacion))
x <- df_regularizacion[, cols]
y <- df$metastasis
# convertir a matriz para incluir interacciones entre todas las variables
#formula <- as.formula(paste("y ~", paste(names(x), collapse = " * "))) # Crear una matriz de diseño con interacciones entre todas las variables
set.seed(1456)
# construimos un grid para encontrar lambda óptimo (el que minimice el error predicho por el modelo vs el dato real)
grid <- 10^seq(1.5, -1.5, length=100)
# y aplicamos ridge (alpha=0)
ridge <- glmnet(x, y, alpha=0, lambda=grid, family="binomial")
dim(coef(ridge))
print(coef(ridge))
plot(ridge, xvar="lambda", label=TRUE) #log lambda plot > nos permite hacernos una idea de por dónde estará el lambda óptimo
x_matrix <- as.matrix(x)
y_matrix <- as.matrix(y)
# hago un m
#modelo de cross validation
ridge_cv <- cv.glmnet(x_matrix, y_matrix, alpha=0, lambda=grid, family="binomial")
lambda_min <- ridge_cv$lambda.min # este es el lambda que menor error nos da para el modelo, me lo guardo en un objeto
# y lo uso para generar modelo de ridge
ridge_cv <- glmnet(x_matrix, y_matrix, alpha=0, lambda = lambda_min, family="binomial")
coefs <- as.data.frame(as.matrix(coef(ridge_cv))) %>% tibble::rownames_to_column(var="Var")#guardar coefs en df
coefs <- coefs[order(-coefs$s0), ] # Ordenar los coeficientes de mayor a menor
head(coefs, 10) # ver los 10 primeros más significativos
set.seed(1456)
grid <- 10^seq(-4,1, lenght=100)
lasso <- glmnet(x, y, alpha=1, lambda=grid, family="binomial")
dim(coef(lasso))
print(coef(lasso))
plot(lasso, xvar="lambda", label=TRUE) #log lambda plot
# hago un modelo de cross validation
grid <- 10^seq(-3,0, lenght=100)
lasso <- cv.glmnet(x_matrix, y_matrix, alpha=1, lambda=grid, family="binomial")
lasso_cv <- glmnet(x_matrix, y_matrix, alpha=1, lambda = lambda_min, family="binomial")
coefs <- as.data.frame(as.matrix(coef(lasso_cv))) %>% tibble::rownames_to_column(var="Var")#guardar coefs en df
# Ordenar los coeficientes de mayor a menor y filtrar los que sean 0
coefs <- coefs[order(-coefs$s0), ] %>% filter(`s0`!=0.000000000000)
coefs # filtrar los que sean
head(coefs, 10) # ver los 10 primeros más significativos
lambda_min <- lasso$lambda.min
lambda_1se <- lasso$lambda.1se
lasso_cv <- glmnet(x_matrix, y_matrix, alpha=1, lambda = lambda_1se, family="binomial")
coefs <- as.data.frame(as.matrix(coef(lasso_cv))) %>% tibble::rownames_to_column(var="Var")#guardar coefs en df
# Ordenar los coeficientes de mayor a menor y filtrar los que sean 0
coefs <- coefs[order(-coefs$s0), ] %>% filter(`s0`!=0.000000000000)
head(coefs, 10) # ver los 10 primeros más significativos
cat("Lambda min:", lambda_min, "\nLambda + 1SE:", lambda_1se)
plot(lasso)# este gráfico nos enseña las variables retenidas para los distintos labmda
set.seed(1456)
seq_alpha <- seq(0.01,0.99,by=0.01) # limitamos el rango para no hacer ni ridge ni lasso
grid <- 10^seq(-3, 3, length=100)
best_alpha <- NULL
best_lambda <- NULL
min_error <- Inf
# encontrar el mejor alpha
for (alpha in seq_alpha) {
enet_cv <- cv.glmnet(x_matrix, y_matrix, alpha=alpha, lambda=grid, family="binomial")
# Obtener valor de lambda óptimo elegido automáticamente
lambda_min<-enet_cv$lambda.min
#Obtener el error de validación cruzada mínimo
cv_error <- min(enet_cv$cvm)
#Actualizar el mejor alpha y lambda si se encuentra un error de cv menor
if (cv_error < min_error) {
min_error <- cv_error
best_alpha <- alpha
best_lambda <- lambda_min
}}
# Imprimir el mejor alpha y lambda encontrados tras el bucle
cat("Mejor alpha:", best_alpha, "\n")
cat("Mejor lambda:", best_lambda, "\n")
grid <- 10^seq(0, -2, length=100)
# hago un modelo de cross validation
enet_cv <- cv.glmnet(x_matrix, y_matrix, alpha=best_alpha, lambda=grid, family="binomial")
plot(enet_cv)
lambda_1se <- enet_cv$lambda.1se
lambda_1se
enet_cv <- glmnet(x_matrix, y_matrix, alpha=best_alpha, lambda=10^-1.3, family="binomial")
coefs_enet <- as.data.frame(as.matrix(coef(enet_cv))) %>% tibble::rownames_to_column(var="Var")#guardar coefs en df
# ordenamos de manera descendente y filtramos los == 0
coefs_enet <- coefs_enet[order(-coefs_enet$s0), ] %>% filter(`s0`!=0.000000000000) %>% # quitamos las == 0
filter(Var != "(Intercept)") # quitamos el intercept
coefs_enet
reg_vars <- c(coefs_enet$Var) # Guardamos variables de elasticnet en vectror
df_regresion <- df_regularizacion %>% dplyr::select(all_of(reg_vars <- c(coefs_enet$Var))) # creamos df_regresion (vacío)
#Tambien hay que añadir la variable categorica
df_regresion$metastasis <- as.factor(df$metastasis)
# Convertimos las variables en tipo factor
for (var in reg_vars) {
if (var %in% colnames(df_char)) { # castear solo las que esten en df_char, que son las tipo factor
df_regresion[[var]] <- as.factor(df_regresion[[var]])
}}
df_regresion <- cbind(df_regresion, df_pca_scores[6:10]) #añadimos al dataframe de regresion los terciles de las PCs
reg_vars <- colnames(df_regresion) #guardo colnames en un vector
reg_vars_x <- setdiff(reg_vars, "metastasis")
formula <- as.formula(paste("metastasis ~", paste(reg_vars_x, collapse = "+")))
modelo_regresion <- glm(formula, data = df_regresion, family = "binomial")
cat("ODDS RATIOS\n")
exp(coef(modelo_regresion)) #OR
cat("\nICs\n")
head(exp(confint(modelo_regresion)), 10) # ver primeros 10 ICs
cat("\nMODEL SUMMARY\n")
rl_summary <- summ(modelo_regresion) #pvalores
rl_summary$coeftable
#Salen cosas muy raras, vamos a ver la colinealidad
vif <- as.data.frame(vif(modelo_regresion))
vif <- vif[order(-vif$`GVIF^(1/(2*Df))`), ]
cat("MODELO 1")
head(vif, 10)
#habria que quitar aquellas variables con un VIF mayor de 5, como sexo, neumopatia, neuropatia, coticoides, secrecion, dolo_abdio, chol, hierro, igN, cpk (realmente los terciles tambien tienen colinealidad pero es raro porque se suponen que vienen de un PCA)
variables_a_eliminar <- c("TPC1", "neumopatia", "neuropatia", "corticoides", "secrecion", "dolor_abdo", "chol", "hierro", "igN", "cpk")
# Eliminar las variables específicas de la fórmula
reg_vars_modificadas <- setdiff(reg_vars_x, variables_a_eliminar)
# Deseleccionar del df
df_regresion_2 <- df_regresion[, reg_vars_modificadas]
# Crear la nueva fórmula con las variables modificadas
formula_modificada <- as.formula(paste("metastasis ~", paste(reg_vars_modificadas, collapse = "+")))
modelo_regresion2 <- glm(formula_modificada, data = df_regresion, family = "binomial")
# Ver resultados
cat("ODDS RATIOS\n")
exp(coef(modelo_regresion2)) #OR
cat("\nICs\n")
round(exp(confint(modelo_regresion2)), 2) # ver primeros 10 ICs
#cat("\nMODEL SUMMARY\n")
#rl_summary_2 <- summ(modelo_regresion2) #pvalores
#rl_summary_2$coeftable
cat("\nVIF\n")
vif2 <- as.data.frame(vif(modelo_regresion2))
vif2 <- vif2[order(-vif2$`GVIF^(1/(2*Df))`), ]
head(vif2, 10)
# Eliminar las variables específicas de la fórmula
reg_vars_modificadas_2 <- c(colnames(df_pca_scores[6:10]))
# Deseleccionar del df
df_regresion_3 <- df_regresion[, reg_vars_modificadas_2]
# Crear la nueva fórmula con las variables modificadas
formula_modificada_2 <- as.formula(paste("metastasis ~", paste(reg_vars_modificadas_2, collapse = "+")))
modelo_regresion3 <- glm(formula_modificada_2, data = df_regresion, family = "binomial")
# Ver resultados
cat("ODDS RATIOS\n")
exp(coef(modelo_regresion3)) #OR
cat("\nICs\n")
round(exp(confint(modelo_regresion3)), 2) # ver primeros 10 ICs
#cat("\nMODEL SUMMARY\n")
#rl_summary_2 <- summ(modelo_regresion2) #pvalores
#rl_summary_2$coeftable
cat("\nVIF\n")
vif3 <- as.data.frame(vif(modelo_regresion3))
vif3 <- vif3[order(-vif3$`GVIF^(1/(2*Df))`), ]
vif3
# Asumiendo que ya tienes un modelo ajustado llamado modelo_logit
# Extraer coeficientes
coeficientes <- coef(modelo_regresion3)
# Calcular Odds Ratios
odds_ratios <- as.data.frame(exp(coeficientes)) %>% tibble::rownames_to_column(var="Var")
intercept <- odds_ratios[1, ]
or_pc1 <- odds_ratios[1:3, ]
or_pc1$PC = "PC1"
or_pc2 <- rbind(intercept, odds_ratios[4:5, ])
or_pc2$PC = "PC2"
or_pc3 <- rbind(intercept, odds_ratios[6:7, ])
or_pc3$PC = "PC3"
or_pc4 <- rbind(intercept, odds_ratios[8:9, ])
or_pc4$PC = "PC4"
or_pc5 <- rbind(intercept, odds_ratios[10:11, ])
or_pc5$PC = "PC5"
OR_d_table <- rbind(or_pc1, or_pc2, or_pc3, or_pc4, or_pc5)
gt(OR_d_table)
kmeans <- kmeans(t(df_genes), centers = 2)
clusters <- list()
for (i in 1:4) {
cluster.plot <- fviz_pca_var(
pca.result, col.var = kmeans$cluster, gradient.cols = c("blue","green", "red"),
axes = c(i,i+1), legend.title ="Clusterizacion", repel = TRUE)
clusters[[i]] <- cluster.plot
}
todos.clusters <- grid.arrange(grobs = clusters, nrow = 2)
todos.clusters
# Asumiendo que ya tienes un modelo ajustado llamado modelo_logit
# Extraer coeficientes
coeficientes <- coef(modelo_regresion3)
# Calcular Odds Ratios
odds_ratios <- as.data.frame(exp(coeficientes)) %>% tibble::rownames_to_column(var="Var")
intercept <- odds_ratios[1, ]
or_pc1 <- odds_ratios[1:3, ]
or_pc1$PC = "PC1"
or_pc2 <- rbind(intercept, odds_ratios[4:5, ])
or_pc2$PC = "PC2"
or_pc3 <- rbind(intercept, odds_ratios[6:7, ])
or_pc3$PC = "PC3"
or_pc4 <- rbind(intercept, odds_ratios[8:9, ])
or_pc4$PC = "PC4"
or_pc5 <- rbind(intercept, odds_ratios[10:11, ])
or_pc5$PC = "PC5"
OR_d_table <- rbind(or_pc1, or_pc2, or_pc3, or_pc4, or_pc5)
gt(OR_d_table)
View(odds_ratios)
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(odds_ratios$`exp(coeficientes)`, breaks = c(0,terciles_OR[1], terciles_OR[2], Inf), labels = c("T1","T2","T3"))
tabla <-  odds_ratios %>%
tbl_summary(by=terciles,
statistic = all_continuous() ~"{p50} ({p25} - {p75})") %>%
add_p(test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
exp(confint(modelo_regresion3))
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
View(ICs)
odds_ratios$IC97 <- ICs$`97.5 %`
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
tabla <- tabla %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
tabla <- tabla %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
#A mi se me habia ocurrido esto, no se que te parece
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(odds_ratios$`exp(coeficientes)`, breaks = c(0,terciles_OR[1], terciles_OR[2], Inf), labels = c("T1","T2","T3"))
tabla <-  odds_ratios %>%
tbl_summary(by=terciles,
statistic = all_continuous() ~"{p50} ({p25} - {p75})") %>%
add_p(test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
#Si a esta tabla le queremos añadir los intervalos de confianza
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
tabla <- tabla %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
#A mi se me habia ocurrido esto, no se que te parece
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(odds_ratios$`exp(coeficientes)`, breaks = c(0,terciles_OR[1], terciles_OR[2], Inf), labels = c("T1","T2","T3"))
#añadir los intervalos de confianza
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = all_continuous() ~ "{p50} ({p25} - {p75})",
include = c(`exp(coeficientes)`, IC2.5, IC97.5)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
) %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
# Crear tabla con `tbl_summary` e incluir intervalos de confianza
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = all_continuous() ~ "{p50} ({p25} - {p75})",
include = c(`exp(coeficientes)`, IC2.5, IC97.5)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
) %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
# Crear una columna con los intervalos de confianza combinados
odds_ratios$IC <- paste0("(", round(odds_ratios$IC2.5, 2), " - ", round(odds_ratios$IC97.5, 2), ")")
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
# Crear una columna con los intervalos de confianza combinados
odds_ratios$IC <- paste0("(", round(odds_ratios$IC2.5, 2), " - ", round(odds_ratios$IC97.5, 2), ")")
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})",
IC ~ "{IC}" # Añade la columna de intervalos
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
# Crear una columna con los intervalos de confianza combinados
odds_ratios$IC <- paste0("(", round(odds_ratios$IC2.5, 2), " - ", round(odds_ratios$IC97.5, 2), ")")
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})"
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
odds_ratios$IC2.5 <- ICs$`2.5 %`
odds_ratios$IC97.5 <- ICs$`97.5 %`
# Crear una columna con los intervalos de confianza combinados
odds_ratios$IC <- paste0("(", round(odds_ratios$IC2.5, 2), " - ", round(odds_ratios$IC97.5, 2), ")")
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})"
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla <- tabla %>%
modify_table_body(
mutate,
IC = paste0("(", round(IC2.5, 2), " - ", round(IC97.5, 2), ")")
)
rm(odds_ratios$IC)
# Calcular Odds Ratios
odds_ratios <- as.data.frame(exp(coeficientes)) %>% tibble::rownames_to_column(var="Var")
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})"
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})"
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
tabla <- odds_ratios %>%
tbl_strata(
strata = terciles,  # Estratificación por terciles, si es necesario
statistic = all_continuous() ~ "{p50} ({p25} - {p75})"
)
tabla <- odds_ratios %>%
tbl_strata(
strata = terciles,  # Estratificación por terciles, si es necesario
statistic = all_continuous() ~ "{p50} ({p25} - {p75})"
)
tabla <- odds_ratios %>%
tbl_strata(
strata = terciles,  # Estratificación por terciles, si es necesario
statistic = all_continuous() ~ "{p50} ({p25} - {p75})"
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
#A mi se me habia ocurrido esto, no se que te parece
# Cálculo de los terciles
terciles_OR <- quantile(odds_ratios$`exp(coeficientes)`, probs = c(1/3, 2/3))
odds_ratios$terciles <- cut(
odds_ratios$`exp(coeficientes)`,
breaks = c(0, terciles_OR[1], terciles_OR[2], Inf),
labels = c("T1", "T2", "T3")
)
# Calcular intervalos de confianza del modelo
ICs <- as.data.frame(exp(confint(modelo_regresion3)))
tabla <- odds_ratios %>%
tbl_summary(
by = terciles,
statistic = list(
all_continuous() ~ "{p50} ({p25} - {p75})"
)
) %>%
add_p(
test = list(all_continuous() ~ "kruskal.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3)
)
tabla
#Quedaria añadir el intervalo de confianza
