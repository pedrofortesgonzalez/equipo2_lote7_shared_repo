df$talla <- ifelse(df$sexo == "Masculino", rnorm(n, mean = 175,  sd = 10),
rnorm(n, mean  = 162, sd = 8))
df$peso <- ifelse(df$sexo == "Masculino", rnorm(n, mean =  80, sd = 10),
rnorm(n, mean = 65, sd = 8))
df$insulina <- ifelse(df$sexo == "Masculino", rnorm(n, mean = 15, sd =5),
rnorm(n, mean = 12, sd = 4))
# Generar ruido en las distribuciones con runif
# La función runif genera valores aleatorios con distribución uniforme dentro de un rango (min, max).
# En este caso, toma un número de registros (calculado con sum()) y sustituye los valores existentes
# por nuevos valores generados aleatoriamente dentro del rango especificado.
df$talla[df$sexo == "Femenino"] <- runif(sum(df$sexo == "Femenino"),
min = 150, max = 180)
#Explicación, en la variable talla, donde  el paciente sea "Femenino", en
#todos los valores femeninos (sum) sustituye los valores por otros uniformemente
#distribuidos en un rango de 150  y 180
df$peso[df$sexo == "Femenino"] <- runif(sum(df$sexo == "Femenino"),
min = 40, max = 150)
df$imc[df$sexo == "Femenino"] <- runif(sum(df$sexo == "Femenino"),
min = 30, max = 45)
df$insulina[df$sexo == "Femenino"] <-  runif(sum(df$sexo == "Femenino"),
min = 20, max = 25)
#Se pueden analizar las variables según el sexo rápidamente
summary(df$peso[df$sexo ==  "Femenino"])
summary(df$peso [df$sexo ==  "Masculino"])
#Adición de otras variables categóricas on sample()
df$estado_salud <- sample(c("Bueno", "Regular", "Malo"), n, replace = TRUE)
df$tratamiento <- sample(c("A", "B", "C"), n, replace = TRUE)
df$tiempo <- sample(c("1 mes", "3 meses", "6 meses", "12 meses"), n, replace =TRUE)
df$dosis <- sample(c("Baja", "Media", "Alta"), n, replace = TRUE)
df$administracion <- sample(c("Oral", "Intravenosa", "Subcutánea"), n, replace = TRUE)
df$pais <- sample(c("EEUU", "España", "México", "Argentina", "Brasil"), n, replace = TRUE)
#Variable: expresion de genes
genes <- c("TNFAIP6", "THBS1", "SERPINE2", "PTX3", "THBS1", "CXCL10",
"CCL4", "SOD2", "IL1B", "CCL20",
"CCL3", "SOD2", "GCH1", "IL8", "ICAM1", "SLC2A6", "BCL2A1",
"TNFAIP2", "SERPINB2", "MAFB")
#Queremos que todos los genes tengan una distribución normal de media 1 y sd 0.2
for (i in genes) {
df[[i]] <- rnorm(n, mean = 1, sd = 0.2)
}
#Ahora la expresión génica va  a variar dependiendo del país
#EEUU
genes_EEUU <- c("TNFAIP6", "THBS1", "SERPINE2", "PTX3")
for (i in genes_EEUU) {
df[[i]][df$pais == "EEUU"] <- rnorm(sum(df$pais ==  "EEUU"),
mean = 3, sd = 2)
} #Si se cumple la condición de pais == EEUU, cambia la distribución
# sino, déjala como está
genes_España <- c("THBS1", "CXCL10", "CCL4", "SOD2")
for (i in genes_España) {
df[[i]][df$pais == "España"] <- rnorm(sum(df$pais == "España"),
mean = 2,  sd = 0.2)
}
genes_Mexico <- c("IL1B", "CCL20")
for (i in genes_Mexico) {
df[[i]][df$pais == "Mexico"] <- rnorm(sum(df$pais == "Mexico"),
mean = 0.5, s = 0.05)
}
genes_Argentina <- c("SOD2", "GCH1", "IL8", "ICAM1", "SLC2A6")
for (i in genes_Argentina) {
df[[i]][df$pais == "Argentina"] <- rnorm(sum(df$pais == "Argentina"),
mean = 4, sd = 0.2)
}
genes_Brasil <- c("BCL2A1", "TNFAIP2", "SERPINB2", "MAFB")
for (i in genes_Brasil) {
df[[i]][df$pais == "Brasil"] <-  rnorm(sum(df$pais == "Brasil"),
mean = 5, sd = 2)
}
#variación de la expresión génica según sexo y estado salud
genes_altos_hombres_malo <- c("TNFAIP6", "THBS1", "IL1B", "IL8", "ICAM1")
for (i in genes_altos_hombres_malo) {
df[[i]] <- ifelse(df$sexo == "Masculino" & df$estado_salud == "Malo",
rnorm(n, mean = 1.5, sd = 0.2), df[[i]])
}
#visualizar valores missing
any(is.na(df)) #no hay valores missing
# Verificar si alguna columna tiene todos los valores iguales a 0
any(colSums(df == 0) == nrow(df))
#Convertir en factor las variabels categoricas
df$sexo <- factor(df$sexo)
df$estado_salud <- factor(df$estado_salud)
df$tratamiento <- factor(df$tratamiento)
df$tiempo <- factor(df$tiempo)
df$dosis <- factor(df$dosis)
df$administracion <- factor(df$administracion)
df$pais <- factor(df$pais)
# Visualizar la estructura de la base de datos
str(df)
levels(df$sexo)
levels(df$estado_salud)
levels(df$tratamiento)
levels(df$tiempo)
levels(df$dosis)
levels(df$administracion)
levels(df$pais)
# Vemos que datos nos han salido
table(df$sexo, df$estado_salud)
table(df$sexo, df$tiempo)
table(df$sexo, df$dosis)
table(df$sexo, df$tratamiento)
#################################################################
#### ---- CONTRASTE DE HIPÓTESIS entre el IMC y el sexo ---- ####
#################################################################
library(car)
#IMC: variable continua
#sexo: variable categórica con dos grupos (k =  2)
# n es mayor de 30 y los datos son independientes
#La hipóotesis nula y la  alternativa son:
# H0: hombres[IMC] = mujeres[IMC] -> p≥0.05
# H1: hombres[IMC] ≠ mujeres[IMC] -> p<0.05
#Se podrá  aplicar t-student si hay homogeneidad de varianzas, sino, test de Welch
# Realizar la prueba de Levene para la homogeneidad de varianzas. Si  (p<0.05) hacer Welch
# H0: varianzas en los grupos son iguales -> p≥0.05
# H1: varianzas en los grupos no son iguales -> p<0.05
resultado_levene_test <- leveneTest(imc ~ sexo, data = df)
print(resultado_levene_test) #se rechazla la hipótesis nula. Se aplica el test de Welch
# Test de Welch
resultado_prueba <- t.test(imc ~ sexo, data = df, equal = FALSE)
print(resultado_prueba)
resultado_prueba$p.value #Se rechaza la hipótesis nula.
#Si se pusiera equal = TRUE, sería la prueba t-student
########################################################################################
#### ---- CONTRASTE DE HIPÓTESIS entre la edad y pacientes con estado de salud ---- ####
########################################################################################
library(ggplot2)
#edad: variable continua
# estado de salud: variable  categórica con tres niveles:
table(df$estado_salud)
#n son pacientes independientes y mayor de 30
#Hipótesis nula y  alternativa:
# H0: bueno[edad] = malo[edad] = regular[edad] -> p≥0.05
# H1: bueno[edad] ≠/= malo[edad] ≠/= regular[edad] -> p<0.05
#Si  la distribución es normal, se aplica ANOVA, sino Kruskal-Wallis
#Se  comprueba la distribución normal con el test de shapiro-wilk:
#H0: los datos siguen una distribución normal p≥0.05
#H1: los datos no siguen una distribución normal p<0.05
shapiro.test(df$edad) #La variable tiene una distribución normal
#Como la distribución es normal, se usa el Test de ANOVA
anova <- aov(edad ~ estado_salud, data = df)
summary(anova) #No se puede  descartar la hipótesis nula
#Con esto no vemos el pvalor para cada pareja de valores.
#Esto se puede analizar gráficamente:
ggplot(data = df, aes(x = estado_salud , y = edad, fill = estado_salud)) +
geom_boxplot() +
geom_jitter(width = 0.2, alpha=0.5) +
theme_classic()
#O con el test de comparaciones múltiples
TukeyHSD(anova)
##################################################################################################
#### ---- CONTRASTE DE HIPÓTESIS entre el tipo de tratamiento y el tiempo de tratamiento ---- ####
##################################################################################################
#Son dos variables categóricas: chi cuadrado ó prueba de Fisher
#Hipótesis nula y alternativa:
# H0: A[tiempo] = B[tiempo] = C[tiempo] -> p≥0.05
# H1: A[tiempo] ≠/= B[tiempo] ≠/= C[tiempo] -> p<0.05
#Se comprueban si las probabilidades son mayores de 5%
prop.table(table(df$tratamiento, df$tiempo))*100 # sacar el % y ver si usar chi cuadrado o Fisher
#Se puede aplicar chi - cuadrado
chisq.test(df$tratamiento, df$tiempo)
#Si hubiera que aplicar Fisher, el código sería:
fisher.test(df$tratamiento, df$tiempo)
#############################################################################################################
#### ---- CONTRASTE DE HIPÓTESIS entre el país de tratamiento y el nivel de expresión de los genes ---- ####
#############################################################################################################
#Queremos ver si, para cada gen, hay una expresión diferencial dependiendo del país
#no vamos a ir de uno en uno sino iterando sobre el vector genes.
#Generamos una tabla, con la variable genes, y el p-valor, que al inicio está vacío
df_resultados <- data.frame(genes = genes, p_valor_disnormal = numeric(length(genes)),
p_valor_anova = numeric(length(genes)))
#Aplicamos el test  de shapiro-wilk a todos los genes
for  (i in 1:length(genes)) {
resultado_shapiro <- shapiro.test(df[[genes[i]]])
df_resultados$p_valor_disnormal[i] <- resultado_shapiro$p.value
}
#Como todos los genes tienen una distribución normal, aplicamos  el  test Anova
for (i in 1:length(genes)) {
resultado_anova <- aov(df[[genes[i]]] ~ pais, data = df)
df_resultados$p_valor_anova[i] <- summary(resultado_anova)[[1]]$`Pr(>F)`[1]  # Accedemos al valor p de ANOVA
}
#Test de comparaciones múltiples
for (i in 1:length(genes)) {
anova <- aov(df[[genes[i]]] ~ pais, data = df)
print(paste("Resultados de Tukey para el gen:", genes[i]))
print(TukeyHSD(anova))
}
##################################
#### ---- Tabla resumen ---- ####
##################################
library(gtsummary)
library(dplyr)
#Para  poder calcular el pvalor y visualizarlo de forma más óptima
# se pueden usar estas tablas, con el argumento add_p
tabla <- df %>%
tbl_strata(strata = tratamiento,
.tbl_fun = ~ .x %>%
tbl_summary(by = sexo,
statistic = all_continuous() ~ "{mean} ({sd})") %>%
add_p(test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3))
)
tabla <- df %>%
tbl_strata(strata=tratamiento,
.tbl_fun = ~.x %>% # es una forma de aplicar una función personalizada a las tablas que creas con el paquete, permite modificar o cambiar esa tabla después de que ha sido creada
tbl_summary(by=sexo,
statistic = all_continuous() ~ "{mean} ({sd})") %>%
add_p(test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3))
)
tabla <- df %>%
tbl_strata(
strata = tratamiento,
.tbl_fun = function(x) {
x %>%
tbl_summary(by = sexo,
statistic = all_continuous() ~ "{mean} ({sd})") %>%
add_p(test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3))
}
)
install.packages("cardx")
tabla <- df %>%
tbl_strata(
strata = tratamiento,
.tbl_fun = function(x) {
x %>%
tbl_summary(by = sexo,
statistic = all_continuous() ~ "{mean} ({sd})") %>%
add_p(test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3))
}
)
tabla <- df %>%
tbl_strata(
strata = tratamiento,
.tbl_fun = function(x) {
x %>%
tbl_summary(by = sexo,
statistic = all_continuous() ~ "{mean} ({sd})") %>%
add_p(test = list(all_continuous() ~ "t.test",
all_categorical() ~ "chisq.test"),
pvalue_fun = ~ style_pvalue(.x, digits = 3))
}
)
install.packages("MASS")
clases_predichas <- lda_pred$class #clases predichas por el modelo
library(MASS)
library(ggplot2)
#Se aplica la función ida sobre el conjunto de entrenamiento
lda_model <- lda(formula_tumor, data = df_train)
rm(list=ls())
set.seed(1995)
library(dplyr)
library(caret)
df <- read.csv("/Users/cristinalazaro/Desktop/UNIR/R/Actividad_1/actividad_1_R/Dataset expresión genes.csv")
##############################################################################
#TRATAMIENTO DE LOS DATOS: EXPRESIÓN GÉNICA SEGÚN EL TIPO DE TUMOR
##############################################################################
#Primer paso: dividir el dataset en grupo de entrenamiento y grupo de
#testing para  construir luego la matriz de confusión
#Antes de eso, del df original, nos quedamos solo con las variables genes
df_genes_tumor <- dplyr::select(df, starts_with("AQ_"), tumor)
df_genes_tumor$tumor <- as.factor(df_genes_tumor$tumor) #convertir a factor
labels_originales <- levels(df_genes_tumor$tumor) #para guardar las
#etiquetas originales
print(labels_originales)
#se ponen los dos puntos porque la librería caret también tiene la función
#select, así se indica que nos referimos a  la librería dplyr
#Usar CreateDataPartition para dividir el df en el grupo de training  y
#el grupo de testing
#Con la función se crean los índices aleatorios que pasan a ser del df de
#entrenamiento. Con p se toma el porcentaje (en tanto por uno) de ínidces
#que pasan a df train
index_train <- createDataPartition(df_genes_tumor$tumor, p = 0.8, list= FALSE)
#Ahora que ya tenemos los índices, lo pasamos a un dataframe
df_train <- df_genes_tumor[index_train, ] #solo x filas, todas las columnas
df_testing <- df_genes_tumor[-index_train, ] #todas menos x filas, todas las columnas
#Podemos ver la cantidad de pacientes que hay en cada dataframe
table(df_train$tumor)
table(df_testing$tumor)
#Escalado de datos
#Solo hay que escalar las variables numéricas.
#Con sapply, elegimos solo las variables numéricas (is.numeric)
#Las variables seleccionadas se acumulan en un nuevo dataframe (numerical_cols)
#Este es el dataframe que se escala (scaled_data)
numerical_cols <- df_train[, sapply(df_train, is.numeric)] #todas las filas
#solo las variables numéricas de df_train
scaled_data <- scale(numerical_cols) #escalado
#Ahora hay que añadir la variable categórica. Hay dos opciones,
#se puede usar mutate() de dplyr, en cuyo caso hay que pasar el resultado
#de scaled_data a dataframe primero, ya que el resultado de scale () es una
#matriz
#La otra opción es usar cbind
df_train <- cbind(scaled_data, tumor = df_train$tumor)
#Hacemos lo mismo para el df de training
numerical_cols_testing <- df_testing[ , sapply(df_testing, is.numeric)]
scaled_data_testing <- scale(numerical_cols_testing)
df_testing <- cbind(scaled_data_testing,  tumor = df_testing$tumor)
#volver a convertir a dataframe y pasar la variable categórica a factor
df_testing <- as.data.frame(df_testing)
df_train <- as.data.frame(df_train)
df_testing$tumor <- as.factor(df_testing$tumor)
df_train$tumor <- as.factor(df_train$tumor)
#Crear la fórmula sumando cada gen (esto es necesario para luego aplicar los
# métodos del discriminantes)
#Primero se seleccionan los nombres de los genes (nombres de los genes de
#de cada columna)
#La función as.formula() devuelve un objeto tipo fórmula de R, que se usa
#para análisis estadísticos
#En este caso, la fórmula establece una relación entre la variable
#dependiente (tumor) y la variable independiente (los genes)
genes <- colnames(df_train[, 1:46])
formula_tumor <- as.formula(paste("tumor ~", paste(genes, collapse = "+")))
formula_tumor
##############################################################################
#TRATAMIENTO DE LOS DATOS: EXPRESIÓN GÉNICA SEGÚN EL TIPO DE TRATAMIENTO
##############################################################################
#Volvemos a dividir el df inicial en grupo de training y grupo de testing
df_genes_tratamiento <- dplyr::select(df, starts_with("AQ_"), trat)
df_genes_tratamiento$trat <- as.factor(df_genes_tratamiento$trat)
index_train_trat <- createDataPartition(df_genes_tratamiento$trat, p = 0.8, list = FALSE)
df_train_tratamiento <- df_genes_tratamiento[index_train_trat, ]
df_test_tratamiento <- df_genes_tratamiento[-index_train_trat, ]
table(df_train_tratamiento$trat)
table(df_test_tratamiento$trat)
df_train_tratamiento_col <- df_train_tratamiento[ , sapply(df_train_tratamiento, is.numeric)]
df_train_tramaiento_scaled <- scale(df_train_tratamiento_col)
df_train_tratamiento <- cbind(df_train_tramaiento_scaled, trat = df_train_tratamiento$trat)
df_test_tratamiento_col <- df_test_tratamiento[ ,sapply(df_test_tratamiento, is.numeric)]
df_test_tratamiento_scaled <- scale(df_test_tratamiento_col)
df_test_tratamiento <- cbind(df_test_tratamiento_scaled, trat = df_test_tratamiento$trat)
genes <- colnames(df_genes_tratamiento[, 1:10])
formula_tratamiento <- as.formula(paste("trat ~ ", paste(genes, collapse = "+")))
formula_tratamiento
df_test_tratamiento <- as.data.frame(df_test_tratamiento)
df_train_tratamiento <- as.data.frame(df_train_tratamiento)
df_test_tratamiento$trat <- as.factor(df_test_tratamiento$trat)
df_train_tratamiento$trat <- as.factor(df_train_tratamiento$trat)
##############################################################################
#                             LDA (lineal)
##############################################################################
library(MASS)
library(ggplot2)
lda_model <- lda(formula_tumor, data = df_train)
lda_model$scaling
#Sobre el resultado de lda, se puede aplicar la función predict() para predecir
#la clasificación de nuevos conjuntos de datos
lda_pred <- predict(lda_model, newdata = df_testing)
lda_pred$class
#Asi tenemos las variables en modo factor, si queremos recuperar las
#clases originales:
predicciones_nombres <-  labels_originales[lda_pred$class]
print(predicciones_nombres)
print(lda_pred$class)
Como en el dataframe df_testing también tenemos las etiquetas reales,
#Como en el dataframe df_testing también tenemos las etiquetas reales,
#podemos generar una matriz de confusión
clases_predichas <- lda_pred$class #clases predichas por el modelo
clases_reales <- df_testing$tumor #clases reales de la base de datos
#Crear la matriz de confusión con confusionMatrix()
confusion_lda <- confusionMatrix(clases_predichas, clases_reales)
print(confusion_lda)
#Gráficos de clasificación
#analizar visualmente el LD1 y LD2, usando el conjunto de prueba
lda_predict_training <- predict(lda_model, newdata = df_train)
lda.data <- cbind(df_train, lda_predict_training$x)
ggplot(lda.data, aes(LD1, LD2))+
geom_point(aes(color=tumor))+theme_classic()
quartz()
ggplot(lda.data, aes(LD1, LD2))+
geom_point(aes(color=tumor))+theme_classic()
pvalues
rm(list = ls())
install.packages("xgboost")
install.packages("randomForest")
library(randomForest) #varimp
install.packages("mda")
setwd("~/Desktop/equipo2_lote7_shared_repo")
library(dplyr)
library(caret)
library(randomForest)
library(klaR)
library(glmnet)
library(pROC)
#Base de datos tratada
df <- read.csv("1_data/df.csv")
x <- as.matrix(df[ ,3:499])
y <- as.factor(df$Clase)
ridge.result <- cv.glmnet(x,y, family = "multinomial", alpha = 0)
ridge.coef <- coef(lasso.result, s = "lambda.min")
ridge.coef <- coef(ridge.result, s = "lambda.min")
# Convertir los coeficientes a matrices
coeff_AGH <- as.matrix(ridge.coef[["AGH"]])
coeff_CFB <- as.matrix(ridge.coef[["CFB"]])
coeff_CGC <- as.matrix(ridge.coef[["CGC"]])
coeff_CHC <- as.matrix(ridge.coef[["CHC"]])
coeff_HPB <- as.matrix(ridge.coef[["HPB"]])
# Convertir las matrices a dataframes, conservando los nombres de las variables
coef_AGH_df <- as.data.frame(coeff_AGH)
coef_CFB_df <- as.data.frame(coeff_CFB)
coef_CGC_df <- as.data.frame(coeff_CGC)
coef_CHC_df <- as.data.frame(coeff_CHC)
coef_HPB_df <- as.data.frame(coeff_HPB)
# Asegurarse de que los nombres de las variables estén en las columnas
colnames(coef_AGH_df) <- "AGH"
colnames(coef_CFB_df) <- "CFB"
colnames(coef_CGC_df) <- "CGC"
colnames(coef_CHC_df) <- "CHC"
colnames(coef_HPB_df) <- "HPB"
# Combinar los dataframes
df_final <- cbind(coef_AGH_df, coef_CFB_df, coef_CGC_df, coef_CHC_df, coef_HPB_df)
View(df_final)
df_final <- df_final[2:199, ] #quitar el intercept
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.1), ]
dim(df_final_2)
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.01), ]
dim(df_final_2)
View(df_final_2)
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.1), ]
dim(df_final_2)
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.5), ]
dim(df_final_2) #71 variables me parece mas razonable
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.1), ]
dim(df_final_2) #71 variables me parece mas razonable
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.05), ]
dim(df_final_2) #71 variables me parece mas razonable
#Eliminamos las variables cuya contribucion a todas las clases sea baja
df_final_2 <- df_final[rowSums(abs(df_final)) > abs(0.1), ]
dim(df_final_2) #71 variables me parece mas razonable
variables_elegidas <- rownames(df_final_2) #variables elegidas
variables_elegidas <- rownames(df_final_2) #variables elegidas
#Del df original, solo nos quedamos con la variable categorica y con las variables numericas seleccionadas
df_analisis <- df %>% dplyr :: select(Clase, all_of(variables_elegidas))
dim(df_analisis) #nos hemos quedado solo con 36 variables, os parecen demasiado pocas??????
#convertir a variable categorica
df_analisis$Clase <- as.factor(df_analisis$Clase)
#Separar en conjunto de entrenamiento y conjunto de prueba
index_train <- createDataPartition(df_analisis$Clase, p = 0.8, list = FALSE)
df_train <- df_analisis[index_train, ]
df_test <- df_analisis[-index_train, ]
#Para los metodos de analisis del discriminante,  hay que aplicar una formula:
formula  <- as.formula(paste("Clase ~ ",paste(variables_elegidas, collapse = "+")))
rda.result <- rda(formula, data = df_train)
rda.prediction <- predict(rda.result, newdata = df_test)
rda.clases <- rda.prediction$class
clases.reales <- df_test$Clase
probabilidades.rda <-  rda.prediction$posterior
matriz.rda <- confusionMatrix(rda.clases, clases.reales)
matriz.rda
svm.result <- train(Clase ~., data = df_train, method = "svmLinear",
trControl = trainControl(method = "cv", number = 5),
prob.model = TRUE, tuneGrid = expand.grid(C =seq(1,20,0.5)))
plot(svm.result) #para ir mirando el valor apropiado de C
svm.prediction <- predict(svm.result, newdata = df_test)
svm.probabilidades <- predict(svm.result, newdata = df_test, type = "prob")
matriz.svm <- confusionMatrix(svm.prediction, clases.reales)
matriz.svm
################################################################################
#                               RANDOM FOREST
################################################################################
#Es mas costoso computacionalmente, pero puede merecer la pena usar un metodo mas robusto para compararlo con los otros dos mas simples
randomforest.result <- train(Clase ~., data = df_train, method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneLength = 30)
plot(randomforest.result)
randomforest.prediction <- predict(randomforest.result, newdata = df_test)
rf.probabilidades <- predict(randomforest.result, newdata = df_test, type = "prob")
rf.matriz <- confusionMatrix(randomforest.prediction,  clases.reales)
rf.matriz
varImp(randomforest.result) #variables mas importantes en el modelo
varImpPlot(randomforest.result$finalModel)
rf.matriz
################################################################################
#                               CURVAS ROC
################################################################################
#Este ejemplo se trata de un problema multiclase:
table(df$Clase)
curva_rda <- multiclass.roc(df_test$Clase, as.matrix(probabilidades.rda))
curva_svm <- multiclass.roc(df_test$Clase, as.matrix(svm.probabilidades))
curva_rf <- multiclass.roc(df_test$Clase, as.matrix(rf.probabilidades))
metodos <- c("RDA", "SVM","RF")
areas <- c(curva_rda$auc,curva_svm$auc, curva_rf$auc)
analisis <- data.frame(modelos = metodos,  AUC = areas) #Pedro, por si quieres usar este df de base para incorporar el resto de parametros
View(analisis)
setwd("~/Desktop/equipo2_lote7_shared_repo")
rm(list = ls())
library(stats)       # Contiene funciones básicas para análisis multivariado, como PCA (prcomp), MDS (cmdscale) y escalado (scale).
library(ggplot2)     # Paquete para crear visualizaciones gráficas, útil para representar resultados en 2D o 3D tras la reducción de dimensionalidad.
library(Rtsne)       # Implementación del método t-SNE, ideal para explorar relaciones no lineales en los datos y visualizarlos en espacios de baja dimensión.
library(FNN)         # Proporciona herramientas para cálculos rápidos de vecinos más cercanos (KNN), necesarias para t-SNE, UMAP, Isomap, entre otros.
library(plotly)      # Permite crear gráficos interactivos en 2D y 3D, facilitando la exploración de los datos proyectados o clusters.
library(factoextra)  # Herramientas para calcular y visualizar resultados de clustering (k-means, clustering jerárquico) y análisis multivariado.
library(cluster)     # Incluye métodos de clustering como k-means, clustering jerárquico (agnes), y divisivo (DIANA).
#Base de datos tratada
df_genes <- read.csv("df.csv")
read.csv("1_data/df.csv")
getwd()
setwd("/Users/cristinalazaro/Desktop/equipo2_lote7_shared_repo/3_xose_equipo2_lote7_shared_repo/")
#Base de datos tratada
df_genes <- read.csv("df.csv")
read.csv("1_data/df.csv")
df_genes <- read.csv("1_data/df.csv")
labels <- read.csv(file.choose(), header = TRUE) # Cargar archivo de classes (con etiquetas de cáncer)
