---
title: "Untitled"
author: "Equipo 2, Lote 7 (Europa)"
date: "2025-01-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = FALSE)
```

# 0.WEnv
```{r}
rm(list=ls()) #resetear WEnv
thisfile_path <- file.choose() #elegir
wd_path <- sub("/[^/]+$", "", thisfile_path) #ruta de este archivo hasta el último "/" (excluyendo nombre del archivo))
setwd(wd_path) #setear wd_path como WD

set.seed(1999) #random seed
library(tidyverse) #ggplot2, dplyr, tidyr, ggpubr, readr...
library(stats) #ops. básicas de estadística
library(factoextra) #
library(pheatmap) #heatmaps
library(gtsummary) #tabla est.descriptiva
library(MASS) 
library(glmnet)
```


# 1.Dataset
```{r}
df <- read.csv("1_data/Dataset expresión genes.csv") # dataframe con todas las variables
               #na.strings = este arg. dice si hay alguna cadena de texto q queramos importar como NA

df_genes <- df %>% dplyr::select(starts_with("AQ_")) # df solo de los genes

dim(df) # dim df
```


# 2.PCA
```{r}
pca.result <- prcomp(df_genes, center = TRUE, scale = TRUE )
pca.result$x
```

# 3.Gráficos descriptivos PCA
## 3.1.¿Cuántos Componentes principales elegimos?
```{r}
#Si miramos los eigenvalues:
eigenvalues <- get_eigenvalue(pca.result)
eigenvalues # Si cogemos las primeras 5 PCs, explicamos > 70% de la varianza > confirmamos con el gráfico
fviz_eig(pca.result, addlabels = TRUE) #
fviz_pca_var(pca.result, col.var = "cos2", gradient.cols = c("blue","yellow", "red"), repel = TRUE) #variables segun calidad cos2

# Contribución de variables a los distintos PCs
fviz_contrib(pca.result, choice ="var", axes = 1, top = 20) #variables que mas influyen a la dimension 1
fviz_contrib(pca.result, choice ="var", axes = 2, top = 20) #variables que mas influyen a la dimension 2
fviz_contrib(pca.result, choice ="var", axes = 3, top = 20) #variables que mas influyen a la dimension 3
```


## 3.2.Clusterizacion
La hacemos para intentar agrupar variables según PCs

### kmeans con 2 centroides
```{r}
kmeans2 <- kmeans(t(df_genes), centers = 2) # hacer clusterización kmeans con 3 clusters
kmeans2$cluster <- as.factor(kmeans2$cluster) # castear variable cluster
summary(kmeans2$cluster)

fviz_pca_var(pca.result, col.var = kmeans2$cluster, legend.title ="Cluster", repel = TRUE)
```
### Resultado del clustering
Tenemos 3 clusters: 2 con 2 variables y otro con 42. Tras buscar 2 genes de cada Cluster en GenBank, nombramos los clusters de la siguiente forma:

- Cluster ADIPOQ y NOX5: **relacionado con el metabolismo celular** (NOX5 está relacionado con el transporte de protones transmembrana) y hormonal (ADIPOQ vinculando a este proceso en el tejido adiposo)
- Cluster CCL5 y TGFB1: **relacionado con el sistema inmune**, ya que CCL5 es una quimiocina y TGFB1 está íntimamente relacionado con sistemas como los interferones.
- Cluster general: contiene genes muy variados y con muchas funciones, como ARG1 (que codifica la Arginasa, encargada de catabolizar el aminoácido Arginina),  LOX5 (que codifica la Lipooxigenasa 5) o MAPK1 (encargada de transducir señales de membrana al núcleo para la transcripción de genes de respuesta a estas). **Por eso lo hemos llamado cluster general**.

## **   Mejorar clusterización??
Tema 4 de algoritmos


### kmeans con 3 centroides --> esto no lo he tocado
```{r}
kmeans3 <- kmeans(df_genes, centers = 3)
fviz_cluster(kmeans3, df_genes) #clusterizacion pacientets

#individuos en las dos primeras dimensiones
fviz_pca_ind(pca.result, col.ind = "cos2", gradient.cols = c("blue","yellow", "red"), repel = TRUE)

df_pca <- as.data.frame(pca.result$x)
df_pca <- df_pca[1:5] #solo estamos analizando los primeros cinco componentes principales

#alguna pareja de componentes permite separar bien los tipos de pacientes ¿?
ggplot(df_pca, aes(x =PC1, y = PC4, color = df$metastasisnosi))+geom_point(size = 3)
```

## 3.3.Aislar 5 primeros PCs?
```{r}
df_5pcs <- pca.result$x[, 1:5] %>% as.data.frame()
```


## 3.4.Regularización
### divisiones del df
```{r}
# las variables factor están en tipo character, tengo que convertirlas a numérico pq glmnet no admite tipo factor
# casteo a numérico variables char
df_nogenes <- df %>% dplyr::select(-starts_with("AQ_"), -X, -id, -extension) # df de vars q no son genes

df_char <- df_nogenes[ ,sapply(df_nogenes, is.character)]# guardamos las vars factor en un vector lógico
df_char$antiemesis <- as.character(ifelse(df$corticoides=="antiemesis", "1", "0"))
df_char$corticoides <- as.character(ifelse(df$corticoides=="si", "1", "0"))

df_nochar <- df_nogenes[, sapply(df_nogenes, is.numeric)]
df_nochar <- as.data.frame(scale(df_nochar, center=TRUE, scale=TRUE))
# convierto variables tipo char a factor y luego a numeros para codificarlas de manera que glmnet las entienda
for (i in colnames(df_char)) {
  df_char[[i]] <-as.numeric(as.factor(df_char[[i]]))
}
# y concateno df_char, df_nochar y df5 pcs en df_lasso
df_lasso <- cbind(df_char, df_nochar)

# ahora tb dejo bien formateada la variable respuesta
df$metastasis = as.factor(as.numeric(ifelse(df$extension == "metastasico", 1, 0)))

# defino variables para df_lasso
cols = c(colnames(df_lasso))
x <- df_lasso[, cols]
y <- df$metastasis

# convertir a matriz para incluir interacciones entre todas las variables
#formula <- as.formula(paste("y ~", paste(names(x), collapse = " * "))) # Crear una matriz de diseño con interacciones entre todas las variables
```


#### ridge
```{r}
# construyo un grid para lambda (para el lambda optimo??)
grid <- 10^seq(1.5, -1.5, length=100)
ridge <- glmnet(x, y, alpha=0, lambda=grid, family="binomial")
dim(coef(ridge))
print(coef(ridge))

plot(ridge, label=TRUE) # lambda plot
plot(ridge, xvar="lambda", label=TRUE) #log lambda plot
```

estos plots nos dan una idea gráfica del valor óptimo de lambda para ridge
```{r}
x_matrix <- as.matrix(x)
y_matrix <- as.matrix(y)
# hago un m
#modelo de cross validation
ridge_cv <- cv.glmnet(x_matrix, y_matrix, alpha=0, lambda=grid, family="binomial")
lambda_min <- ridge_cv$lambda.min # este es el lambda que menor error nos da para el modelo, me lo guardo en un objeto
# y lo uso para generar modelo de ridge
ridge_cv <- glmnet(x_matrix, y_matrix, alpha=0, lambda = lambda_min, family="binomial")
coef(ridge_cv)
```

Todas las variables tienen valores muy bajos... Creo que sería ideal eliminar algunas

#### lasso
```{r}
grid <- 10^seq(-4,1, lenght=100)
lasso <- glmnet(x, y, alpha=1, lambda=grid, family="binomial")
dim(coef(lasso))
print(coef(lasso))

plot(lasso, label=TRUE) # lambda plot
plot(lasso, xvar="lambda", label=TRUE) #log lambda plot
```

estos plots nos dan una idea gráfica del valor óptimo de lambda para ridge
```{r}
# hago un modelo de cross validation
grid <- 10^seq(-3,0, lenght=100)
lasso_cv <- cv.glmnet(x_matrix, y_matrix, alpha=1, lambda=grid, family="binomial")
plot(lasso_cv)
```

El lambda min me dejará solo una variable (intercepto), pero podemos usar otra regla: en vez de el lambda mínimo, usamos el lambda "within one standard error from the minimum" --> lambda que minimiza el CV error + 1 SE (si no, el valor de lambda mínimo se carga todas las variables)

```{r}
lambda_min <- lasso_cv$lambda.min
lambda_1se <- lasso_cv$lambda.1se # este es el lambda que menor error nos da para el modelo, me lo guardo en un objeto
# y lo uso para generar modelo de ridge
lasso_cv <- glmnet(x, y, alpha=1, lambda = lambda_1se, family="binomial")
coef(lasso_cv)
```

#### elastic net
```{r}
seq_alpha <- seq(0,1,by=0.01)
grid <- 10^seq(3, -3, length=100) # lo hago de + a - pq el lambda óptimo  es negativo (ver plots iniciales de lasso)

best_alpha <- NULL
best_lambda <- NULL
min_error <- Inf

# encontrar el mejor alpha
for (alpha in seq_alpha) {
  enet_cv <- cv.glmnet(x_matrix, y_matrix, alpha=alpha, lambda=grid, family="binomial")
  # Obtener valor de lambda óptimo elegido automáticamente
  lambda_min<-enet_cv$lambda.min
  #Obtener el error de validación cruzada mínimo
  cv_error <- min(enet_cv$cvm)
  #Actualizar el mejor alpha y lambda si se encuentra un error de cv menor
  if (cv_error < min_error) {
    min_error <- cv_error
    best_alpha <- alpha
    best_lambda <- lambda_min
  }}

# Imprimir el mejor alpha y lambda encontrados tras el bucle
cat("Mejor alpha:", best_alpha, "\n")
cat("Mejor lambda:", best_lambda, "\n")
```


```{r ejecutar elasticnet}
grid <- 10^seq(0, -2, length=100)
# hago un modelo de cross validation
enet_cv <- cv.glmnet(x_matrix, y_matrix, alpha=0.67, lambda=grid, family="binomial")
plot(enet_cv)
lambda_1se <- enet_cv$lambda.1se
lambda_1se
```

```{r}
enet_cv <- glmnet(x_matrix, y_matrix, alpha=0.36, lambda=10^-1, family="binomial")
coefs_enet <- as.data.frame(as.matrix(coef(enet_cv))) %>% filter(s0!=0)
coefs_enet <- coefs_enet %>% slice_tail(n = 18) # quitamos el intercept
reg_vars <- rownames(coefs_enet)
df <- df
df_rl <- 
```

Variables de regularización están en un vector `reg_vars`.

Ahora hay que calcular terciles de las PCs (`df_5pcs`)
```{r}
for (i in )
```


# 4.Tabla descriptiva
```{r}
for (i)
```


variables dummy
$$
baseline = T1 \rightarrow\text{para los 5 PCs} \\

metastasis = PC1T2\times\beta_{PC1T2} + PC1T3\times\beta_{PC1T3} + \\
PC2T2\times\beta_{PC1T2} + PC2T3\times\beta_{PC1T3} + \\
PC3T2\times\beta_{PC1T2} + PC3T3\times\beta_{PC1T3} + \\
PC4T2\times\beta_{PC1T2} + PC4T3\times\beta_{PC1T3} + \\
PC5T2\times\beta_{PC1T2} + PC5T3\times\beta_{PC1T3}
$$

# 5.Modelo predictivo Reg.Logística
output = df$metastasisino
input = df$PC1:5, df$ que no estén en df_genes 
```{r}
pcs = c("PC1", "PC2", "PC3", "PC4", "PC5")
df_pca <- df_pca %>% dplyr::select(pcs)
df_rlog =  cbind(df_pca, df_nogenes)

# selecciono vars_num
df_non_numeric <- df %>% keep(~ !is.numeric(.))

# recodificar vars factor y chr como números --> castear a as.numeric()
for (col in names(df_non_numeric)) {
  if ("si" %in% col){
    gsub("si", "1", col)
  } else if ("no" %in% col) {
    gsub("no", "0", col)
  }
}

df_non_numeric

df_non_numeric <- df_non_numeric %>% gsub('si', "1", df_non_numeric)
df_non_numeric <- df_non_numeric %>% gsub('no', "0", df_non_numeric)
df_non_numeric
```

## terciles PCs
```{r}
# terciles PC1 --> factor var
df_rlog$`Terciles PC1` <- quantile()

# terciles PC2 (lo mismo que antes)
# terciles PC3 (lo mismo que antes)
# terciles PC4 (lo mismo que antes)
# terciles PC5 (lo mismo que antes)
```

